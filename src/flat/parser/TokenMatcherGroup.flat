package flat/parser

import flat/datastruct/HashMap
import flat/datastruct/list/Queue
import flat/compiler/models/Token
import flat/log/Logger

data class extends TokenMatcher {
  let static Logger log = Logger(TokenMatcherGroup.class)

  override let lazy Int requiredTokenCount => matchers.sum({ _.requiredTokenCount })

  public construct(
    visible Array<TokenMatcher> matchers,
    this Bool optional = false,
    this Bool repeat = false,
    this Bool greedy = true
  ) {}

  override public matches(
    var Token[] tokens,
    Bool requireAllTokensConsumed = true
  ) -> TokenMatch => null {
    log.traceFunc({"No tokens. Skipping match"})
    if (tokens.isEmpty) return null

    tokens = tokens.toArray()

    let outputLabels = HashMap<String, Array<String>>()
    let matchedTokens = Token[]
    let matcherator = matchers.iterator

    while (matcherator.hasNext) {
      let matcher = matcherator.stepNext

      if (matcher.optional && !matcher.greedy) {
        if (matcherator.hasNext && matcherator.next.matches(tokens, false)) {
          log.traceFunc({"Matcher is optional and non-greedy, and the next matcher matches, so skipping to that"})
          continue
        }
      }

      var match = matcher.matches(tokens, false)

      if (!match) {
        if (matchedTokens.isNotEmpty && tokens.isEmpty) {
          if (matcherator.allNextInclusive.all({ _.optional })) {
            break
          }
          log.traceFunc({"|
            Returning partial match
              tokens: [#{tokens.map(t => "'" + t.value + "'").join(", ")}]
              matchedTokens: [#{matchedTokens.map(t => "'" + t.value + "'").join(", ")}]
              submatcher: #{matcher}
              matcher: #{this}
            |"})
          return TokenMatch(matchedTokens, outputLabels, partial: true)
        }
        break
      }

      log.traceFunc({"|
        Matched
          tokens: [#{tokens.map(t => "'" + t.value + "'").join(", ")}]
          match: #{match}
          submatcher: #{matcher}
          matcher: #{this}
        |"})

      if (matcher.repeat && !matcher.greedy) {
        if (matcherator.hasNext && matcherator.next.matches(tokens, false)) {
          continue
        }
      }

      while (match && tokens.isNotEmpty && match.tokens.isNotEmpty) {
        match.tokens.forEach({ tokens.shift() })

        matchedTokens.addAll(match.tokens)
        match.values.forEach((entry) => {
          outputLabels.getOrDefault(entry.key, { Array() }).addAll(entry.value)
        })

        if (!matcher.repeat || tokens.isEmpty) {
          break
        }

        match = matcher.matches(tokens, false)
      }
    }

    if (!requireAllTokensConsumed || tokens.isEmpty) {
      if (matcherator.allNext.any({ !_.optional })) {
        return null
      }
      log.traceFunc({"|
        Returning complete match
          tokens: [#{tokens.map(t => "'" + t.value + "'").join(", ")}]
          matchedTokens: [#{matchedTokens.map(t => "'" + t.value + "'").join(", ")}]
          matcher: #{this}
        |"})
      return TokenMatch(matchedTokens, outputLabels, partial: false)
    }
  }
}