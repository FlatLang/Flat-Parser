package flat/parser

import flat/datastruct/list/Stack
import flat/ast/Node
import flat/ast/AnnotationNode
import flat/ast/FileNode
import flat/compiler/models/Token
import flat/io/File
import flat/log/Logger
import flat/stream/Stream

class {
  let static Logger log = Logger(Parser.class)

  public async parse(File file, Stream tokenStream) -> Stream {
    let fileNode = FileNode(file: file)

    return parse(fileNode, tokenStream)
  }

  async parse(FileNode fileNode, Stream tokenStream) -> Stream {
    let stream = Stream(true)

    let handler = ParseHandler(fileNode, stream)

    tokenStream.on<Token>("data", (token) => {
      Parser.log.traceFunc({"Received data from Token Stream: #{token}"})

      handler.consume(token)
    })$

    tokenStream.on<String>("error", (error) => {
      Parser.log.traceFunc({"Received error from Token Stream: #{error}"})
      stream.emit("error", error)$
    })$

    tokenStream.on("close", {
      Parser.log.traceFunc({"Token Stream closed"})
      stream.emit("close")$
    })$

    return stream
  }

  private class ParseHandler {
    Stack<Node> parentStack = Stack()
    Stack<ParserBase> parserStack = Stack()

    let AnnotationParser annotationParser = AnnotationParser()

    var ParserResult[] currentResults = ParserResult[]
    var Token[] tokens = Token[]
    var ParseContext context = ParseContext()

    construct(
      private FileNode fileNode,
      private Stream stream
    ) {
      parentStack.push(fileNode)
      parserStack.push(FileParser())
      context = context.copy(parent: parentStack.peek())

      resetCurrentResults()
    }

    resetCurrentResults() {
      currentResults = parserStack.peek().childParsers.map({ ParserResult(_, null) })
      context = context.copy(annotations: AnnotationNode[])
    }

    async consume(Token token) {
      if (token.type == Token.Type.WS) return

      let parent = parentStack.peek()
      let parser = parserStack.peek()

      tokens.add(token)

      Parser.log.debugFunc({"Matching tokens: [#{tokens.map(t => "'" + t.value + "'").join(", ")}]"})

      if (let annotationMatch = annotationParser.pattern.matches(tokens)) {
        Parser.log.debugFunc({"Matched annotation: #{annotationMatch}"})

        if (annotationMatch.partial) {
          return
        }

        let annotation = annotationParser.generateNode(context, annotationMatch)

        Parser.log.debugFunc({"Parsed annotation: #{annotation}"})

        context.annotations.add(annotation)
      }

      let results = currentResults.mapNotNullAsync((result) => {
        if (let match = result.parser.pattern.matches(tokens)) {
          return result.copy(match: match)
        }

        return null
      }).toArray()

      if (results.isEmpty) {
        if (currentResults.count == 1) {
          let result = currentResults.first

          if (!result.match.partial) {
            let matchedTokens = result.match.tokens
            tokens = tokens.skip(matchedTokens.count)

            let node = result.parser.generateNode(context, result.match)

            stream.emit("data", node)$
          }
        } else {
          // throw syntax error
          tokens = Token[]
        }

        resetCurrentResults()
      } else {
        currentResults = results
      }
    }

    private data class ParserResult {
      visible ParserBase parser
      visible TokenMatch match
    }
  }
}